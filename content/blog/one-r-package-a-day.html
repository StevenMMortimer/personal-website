---
title: One R Package a Day
author: Steven M. Mortimer
date: '2018-06-27T06:00:00'
slug: one-r-package-a-day
categories:
  - R
tags:
  - r-code
  - CRAN
  - GitHub
  - Python
  - Heroku
description: "This post describes how the Twitter bot @RLangPackage was created."
image: "blog/one-r-package-a-day/profile-pic.png"
output:
  blogdown::html_page
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p><img src="/blog/one-r-package-a-day/profile-pic.png" /></p>
<p>Discover one R package a day by following the
<a target="_blank" href="https://twitter.com/RLangPackage"><span class="citation">@RLangPackage</span></a> account
on Twitter! Inspired by One R Tip Day
(<a target="_blank" href="https://twitter.com/RLangTip"><span class="citation">@RLangTip</span></a>) I created
a Twitter bot that will feature one package with its description and GitHub URL
each day. The R programming language (referred to as
<a target="_blank" href="https://twitter.com/hashtag/rstats">#rstats</a> on
Twitter) now has over 12,600 packages. Tweeting one each day would take more
than 34 years to get through them all and that doesn’t even consider the rapid
growth of new packages as shown in this
<a target="_blank" href="ttp://blog.revolutionanalytics.com/2017/01/cran-10000.html">post</a>.</p>
<p><img src="/blog/one-r-package-a-day/r-package-growth.png" /></p>
<p>The purpose of the <a target="_blank" href="https://twitter.com/RLangPackage"><span class="citation">@RLangPackage</span></a>
Twitter account is to feature the diversity of packages that R has to offer. Most
users have heard of <strong>ggplot2</strong> and <strong>dplyr</strong>, but there are thousands of other great
packages waiting to be discovered. In order to highlight those I took a list of all
packages on CRAN and filtered it down to ones with anywhere between 5,000 and
1,000,000 CRAN downloads. I then took a subset of that with anywhere between 10
and 1,000 stars on GitHub. I decided to focus on these mildly popular packages with
source code hosted on GitHub so that I can embed the link in the tweet and promote packages with
code that people have already started to explore. After following those subsetting rules,
one package is selected at random after narrowing to a list of packages that haven’t
already been tweeted. I am hosting the bot on Heroku and using Heroku Scheduler to
send out a tweet each day at 10:30am UTC or 6:30am Eastern Time. Below the credits
and resources is the sloppily written Python that’s currently being hosted on
Heroku and executed.</p>
<div id="credits" class="section level2">
<h2>Credits</h2>
<p>I was found a couple different blog posts on creating a Twitter bot with R, namely
<a target="_blank" href="https://medium.com/@randerson112358/create-a-twitter-bot-using-r-5a94f1b1b886">here</a> and
<a target="_blank" href="https://rstudio-pubs-static.s3.amazonaws.com/54352_3afcd597884a4192b3361513f2d32699.html">here</a>,
but they didn’t involve deploying on Heroku or another cloud service. However, there were
plenty of Python based Twitter bot tutorials, so I took full advantage of them and went the Python route.
Below is the host of resources I considered while figuring out how to deploy the app, what Twitter
package to use, and some basic Python syntax which, embarrassingly, I should know by now.
I think most users will gravitate towards the <strong>tweepy</strong> Python library but I found that
it throws up an error when using it with Conda 3.6. The issue is documented on GitHub
<a target="_blank" href="https://github.com/tweepy/tweepy/issues/894">https://github.com/tweepy/tweepy/issues/894</a>.</p>
<p><strong>Resources</strong></p>
<ul>
<li>Used as a general guide to deploying: <a href="http://briancaffey.github.io/2016/04/05/twitter-bot-tutorial.html" class="uri">http://briancaffey.github.io/2016/04/05/twitter-bot-tutorial.html</a></li>
<li>Setting up credentials as config vars: <a href="https://devcenter.heroku.com/articles/config-vars" class="uri">https://devcenter.heroku.com/articles/config-vars</a></li>
<li>How to load environment vars from file: <a href="https://robinislam.me/blog/reading-environment-variables-in-python/" class="uri">https://robinislam.me/blog/reading-environment-variables-in-python/</a></li>
<li>Timeline dump code: <a href="https://github.com/geduldig/TwitterAPI/blob/master/examples/dump_timeline.py" class="uri">https://github.com/geduldig/TwitterAPI/blob/master/examples/dump_timeline.py</a></li>
</ul>
</div>
<div id="full-script" class="section level2">
<h2>Full Script</h2>
<pre class="python"><code># script.py
from os import environ
from os.path import join, dirname
from dotenv import load_dotenv
from re import sub
import pandas
from TwitterAPI import TwitterAPI, TwitterPager

# create .env file path
dotenv_path = join(dirname(__file__), &#39;.env&#39;)

# load file from the path
load_dotenv(dotenv_path)

if __name__ == &quot;__main__&quot;:

    # connect to api
    api = TwitterAPI(consumer_key=environ[&#39;TWITTER_CONSUMER_KEY&#39;],
                     consumer_secret=environ[&#39;TWITTER_CONSUMER_SECRET&#39;],
                     access_token_key=environ[&#39;TWITTER_ACCESS_TOKEN&#39;],
                     access_token_secret=environ[&#39;TWITTER_ACCESS_TOKEN_SECRET&#39;])

    # scrape all prior tweets to check which packages I&#39;ve already tweeted about
    SCREEN_NAME = &#39;RLangPackage&#39;
    pager = TwitterPager(api,
                         &#39;statuses/user_timeline&#39;,
                         {&#39;screen_name&#39;: SCREEN_NAME, &#39;count&#39;: 100})

    # parse out the package name that occurs before the hyphen at the beginning
    previous_pks = []
    for item in pager.get_iterator(wait=3.5):
        if &#39;text&#39; in item:
            this_pkg = sub(&quot;^(\w+) - (.*)&quot;, &quot;\\1&quot;, item[&#39;text&#39;])
            previous_pks.append(this_pkg)

    # convert the package names to a dataframe
    prev_df = pandas.DataFrame({&#39;name&#39;: previous_pks})
    prev_df.set_index(&#39;name&#39;)

    # load the data I&#39;ve compiled on R packages
    url = &quot;https://raw.githubusercontent.com/StevenMMortimer/one-r-package-a-day/master/r-package-star-download-data.csv&quot;
    all_df = pandas.read_csv(url)
    all_df.set_index(&#39;name&#39;)

    # do an &quot;anti join&quot; to throw away previously tweeted rows
    all_df = pandas.merge(all_df, prev_df, how=&#39;outer&#39;, indicator=True)
    all_df = all_df[all_df[&#39;_merge&#39;] == &#39;left_only&#39;]

    # focus on packages in middle ground of downloads and stars
    filtered_df = all_df[all_df[&#39;stars&#39;].notnull()]
    filtered_df = filtered_df[filtered_df[&#39;stars&#39;].between(10,1000)]
    filtered_df = filtered_df[filtered_df[&#39;downloads&#39;].notnull()]
    filtered_df = filtered_df[filtered_df[&#39;downloads&#39;].between(5000, 1000000)]

    # randomly select one of the remaining rows
    selected_pkg = filtered_df.sample(1)

    # pull out the name and description to see if we need to 
    # truncate because of Twitters 280 character limit
    prepped_name = selected_pkg.iloc[0][&#39;name&#39;]
    prepped_desc = sub(&#39;\s+&#39;, &#39; &#39;, selected_pkg.iloc[0][&#39;description&#39;])

    name_len = len(prepped_name)
    desc_len = len(prepped_desc)

    # 280 minus 3 for &quot; - &quot;, then minus 23 because links are counted as such,
    # then minus 9 for the &quot; #rstats &quot; hashtag
    if desc_len &lt;= (280-3-23-9-name_len):
        prepped_desc = prepped_desc[0:desc_len]
    else:
        prepped_desc = prepped_desc[0:(280-6-23-9-name_len)] + &quot;...&quot;

    # cobble together the tweet text
    TWEET_TEXT = prepped_name + &quot; - &quot; + prepped_desc + &quot; #rstats &quot; + selected_pkg.iloc[0][&#39;github_url&#39;]
    print(TWEET_TEXT)

    # tweet it out to the world!
    r = api.request(&#39;statuses/update&#39;, {&#39;status&#39;: TWEET_TEXT})
    print(&#39;SUCCESS&#39; if r.status_code == 200 else &#39;PROBLEM: &#39; + r.text)</code></pre>
</div>
